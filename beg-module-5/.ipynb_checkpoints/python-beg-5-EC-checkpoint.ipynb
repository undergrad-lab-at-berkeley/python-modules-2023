{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ULAB Physics & Astronomy: Python Module V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T05:43:05.617652Z",
     "start_time": "2021-08-07T05:43:04.349617Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tests\n",
    "import utils\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy\n",
    "\n",
    "Numpy is a fast and convenient package for working with numerical data. In this module, we will review some basic Numpy concepts by creating a basic music synthesizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will quickly review a couple numpy operations so that you feel more prepared to build the synthesizer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some numpy functions you may be using in this module.\n",
    "1. np.array\n",
    "2. np.arange\n",
    "3. np.linspace\n",
    "3. np.where\n",
    "4. np.abs\n",
    "5. np.ones/np.zeros\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a numpy array containing 5 random integers, and assign it to variable `arr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO\n",
    "arr = np.arange(0,5)\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Add 25 to each element in `arr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "arr_plus_25 = np.arange(0, 5)+25\n",
    "arr_plus_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a new array that contains numbers from 1 to 100 and assign it to one_to_hundred. DON'T make this using `np.array`.\n",
    "\n",
    "Hint: `np.arange` might help! If you're not sure how to use an inbuilt or existing function, call `help` on the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example,\n",
    "help(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "one_to_hundred = ...\n",
    "one_to_hundred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now make an array containing the multiples of 13 starting from 0! The array should have 300 elements. Try doing this with `np.arange` and `np.linspace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "multiples_arange = ...\n",
    "multiples_arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, and make sure your array has the correct number of elements.\n",
    "print(f'Multiples has {len(multiples_arange)} elements.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "multiples_linspace = ...\n",
    "multiples_linspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, and make sure your array has the correct number of elements.\n",
    "print(f'Multiples has {len(multiples_linspace)} elements.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change num_zeros and see what happens\n",
    "num_zeros = 10\n",
    "np.zeros(num_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change num_ones and see what happens\n",
    "num_ones = 25\n",
    "np.ones(num_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This module will require playing audio. Run the cell below to play a segment of audio and adjust your computer volume so it is not too loud or quiet (note: do NOT adjust the volume next to the three vertical dots). \n",
    "\n",
    "***The audio in these exercises have been \"normalized\" so that it is roughly the same volume as the audio below. However you may accidentally generate very loud noises. Take caution with headphones.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T05:44:16.114804Z",
     "start_time": "2021-08-07T05:44:15.958565Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libertango, Astor Piazzolla, Yo-Yo Ma\n",
    "ipd.Audio('samples/libertango.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WAV Files\n",
    "\n",
    "A .WAV file stores audio information as a raw bitstream. In essence, this bitstream is a list voltages for your speaker to play. Most commonly, audio is sampled at 44.1 KHz at 16 bit-depth. This means that every 44,100 times a second, a value for the sound wave at that time is digitized to a 16-bit integer.\n",
    "\n",
    "<img src=\"fig/pcm.png\"  style=\"width: 600px;\"/>\n",
    "\n",
    "In the image above, the physical sound wave (red) is sampled (blue) and converted to an array (WAV file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T06:32:01.311683Z",
     "start_time": "2021-08-03T06:32:01.151669Z"
    }
   },
   "source": [
    "## Question 0: A Pure Tone\n",
    "\n",
    "Since a WAV file is simply an array, why can't we generate our own music with a bit of math? This is exactly what you're going to do in the sections below!\n",
    "\n",
    "To start, generate a sin tone with frequency 220 Hz (A3). The tone is described by the equation:\n",
    "\n",
    "$$f(t) = A\\sin(2\\pi f t)$$\n",
    "\n",
    "Where:\n",
    "$f$ is the frequency,\n",
    "\n",
    "$t$ is the time of each sample (the time of the n-th sample is at time $t_n = n/$sample rate),\n",
    "\n",
    "$A = 0.3\\cdot32767$.\n",
    "\n",
    "\n",
    "Note: 32767 is the maximum volume of a 16-bit number. If our sine wave were to have an amplitude of 32767, we would be telling our speaker to play at the max of the computer volume. This doesn't sound good: it's too loud and speakers tend to make clicking noises. Thus, we normalize the audio to a more reasonable level by multiplying by the factor 0.3.\n",
    "\n",
    "### 0a (5 pts)\n",
    "Generate a numpy array with the values of `t` for ```samps``` number of samples. The `ith` value in the array `t` should contain the time of the `ith` sample. Hint: ```np.arange``` and/or ```np.linspace```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T05:47:09.900666Z",
     "start_time": "2021-08-07T05:47:09.801560Z"
    }
   },
   "outputs": [],
   "source": [
    "# note that the same rate, amplitude corresponding to maximum volume and the number of samples has been provided.\n",
    "# if you're curious about how some function works, use the help function but you don't have to know anything that we have\n",
    "# provided!\n",
    "\n",
    "samplerate = 44100\n",
    "\n",
    "maxint = np.iinfo(np.int16).max #32767\n",
    "samps = 2*samplerate # 2 seconds\n",
    "\n",
    "t = ...\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T05:47:10.974569Z",
     "start_time": "2021-08-07T05:47:10.929047Z"
    }
   },
   "outputs": [],
   "source": [
    "tests.run('test_0a', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T06:16:11.064649Z",
     "start_time": "2021-08-03T06:16:10.905568Z"
    }
   },
   "source": [
    "### 0b (10 pts)\n",
    "Now, complete the function ```ptone``` which generates a pure tone of frequency ```freq``` that is ```samps``` samples long. **Use the samplerate and value for $A$ above.** \n",
    "\n",
    "*Hint: Use numpy for any mathematical operations. Eg: `np.sin`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T05:47:29.818431Z",
     "start_time": "2021-08-07T05:47:29.779649Z"
    }
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "def ptone(freq, samps):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we generate and play a 2-second long, 220 Hz tone with ```ptone```. **NOTE: if you see `autoplay=True`, audio will play immediately after you run the cell!** You can toggle this off by setting `autoplay` to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:23:26.874904Z",
     "start_time": "2021-08-07T06:23:26.793196Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# should sound quiet. Most speakers have a bit of trouble generating tones this low.\n",
    "pure_tone = ptone(220, 2*samplerate)\n",
    "utils.save(pure_tone)\n",
    "print('Your tone:')\n",
    "ipd.display(ipd.Audio('out/tone.wav', autoplay=False))\n",
    "print('Your tone should sound like: ')\n",
    "ipd.display(ipd.Audio('samples/pure_a.wav', autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Timbre\n",
    "\n",
    "The frequency 220 Hz corresponds to the A string on a cello. However, the audio generated above is not recognizable as a cello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:23:32.288091Z",
     "start_time": "2021-08-07T06:23:32.246248Z"
    }
   },
   "outputs": [],
   "source": [
    "# audio of cello A string\n",
    "ipd.Audio('samples/cello_a.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the pure tone and the cello have the same pitch, but have different qualities. This \"quality\" of sound is known as timbre. When the A-string of a cello is bowed (played), the fundamental frequency, 220 Hz, is excited. In addition, frequencies that are integer multiples of the fundamental (harmonics) are also excited. The resonance of the cello (i.e. the structure of the cello) amplifies the harmonics by different amounts. Thus, the shape of the harmonics forms a unique signature or timbre of an instrument. This is how we can differentiate a cello playing A3 from a piano playing the same note.\n",
    "\n",
    "We can determine what how much of each frequency is present in a sound by performing a Fourier transform. This is a mathematical technique to determine how much of each frequency is present in a section of audio.\n",
    "\n",
    "We have implemented for you two functions in the ```utils``` module: ```plot_fft``` and ```fft```. You will also find the the ```input``` function in the ```utils``` module useful. (FFT stands for the fast Fourier transform)\n",
    "\n",
    "Let's plot the Fourier transform of our pure and real tone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T05:58:09.551938Z",
     "start_time": "2021-08-07T05:58:08.119467Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_fft(pure_tone, title='Spectrum of Pure Tone (220 Hz)')\n",
    "\n",
    "real = utils.input('samples/cello_a.wav') # utils.input reads in a WAV file as a list\n",
    "utils.plot_fft(real, title='Spectrum of Real Cello (220 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spectrum of the pure tone is as expected: a single peak at 220 Hz. However, the spectrum of the cello is much more rich---14 harmonics and counting! What may also be surprising is that the 1st, 2nd, 3rd, and 8th harmonics have a larger amplitude than the fundamental. \n",
    "\n",
    "\n",
    "**Side note:** this is _exactly_ what's happening in your ear. Sound waves that enter your ear are Fourier transformed by the ear's internal structure. High frequencies are coupled to pressure waves near the base of your cochlea (purple structure) while low frequencies are coupled to pressure waves at the tip of your cochlea. Along the length of the cochlea are hairs that senses changes in pressure and trigger signals to your auditory cortex. The location of the hair along the cochlea corresponds to a frequency range; thus, each hair is responsible for detecting a small range of frequencies!\n",
    "\n",
    "<img src=\"fig/ear.png\"  style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a (5 pts)\n",
    "\n",
    "Read the docstring for the ```fft``` function in ```utils``` and determine the frequencies ```f``` and Fourier coefficients ```fft``` for the cello.\n",
    "\n",
    "Hint 1: You'll need to use the variable ```real```.\n",
    "\n",
    "Hint 2: If you're not sure how `utils.fft` works, call help on it just like we showed you before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell to if you need to call help on utils.fft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T05:59:50.738427Z",
     "start_time": "2021-08-07T05:59:50.671127Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, fft = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Frequencies: {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Fourier coefficients: {fft}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T05:59:51.615927Z",
     "start_time": "2021-08-07T05:59:51.561143Z"
    }
   },
   "outputs": [],
   "source": [
    "tests.run('test_1a', f, fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b (5 pts)\n",
    "\n",
    "In order to determine the amplitudes of the first 15 harmonics, it would not be correct to find the amplitudes that correspond to the frequencies 220, 440, etc. This is because it is not guaranteed that the peak of each harmonic is at the exact frequency (the cello can't be exactly in tune). Instead, we need to search all amplitudes withing 1 Hz of the harmonic.  \n",
    "\n",
    "Using ```np.where``` and ```np.abs```, find the Fourier coefficients of all frequencies within 1 Hz of 220 Hz. Determine the maximum coefficient, this is the peak.\n",
    "Hint: Think about what np.where returns and how you can use that! Remember that you can index into a numpy array with an array like this:\n",
    "```python\n",
    ">>> a = np.arange(1,11)\n",
    "# a = array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    ">>> b = np.array([2,4,6,8])\n",
    "# here, we are indexing into a using b\n",
    ">>> a[b]\n",
    "array([3, 5, 7, 9])\n",
    "```\n",
    "`a[b]` displays the elements of `a` at index 2, 4, 6 and 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:02:13.883500Z",
     "start_time": "2021-08-07T06:02:13.847817Z"
    }
   },
   "outputs": [],
   "source": [
    "indices_of_wanted_frequencies = ...\n",
    "coeffs = ...\n",
    "peak = ...\n",
    "print(coeffs)\n",
    "print(peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:02:14.709478Z",
     "start_time": "2021-08-07T06:02:14.661202Z"
    }
   },
   "outputs": [],
   "source": [
    "tests.run('test_1b', coeffs, peak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c (5 pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part b, you determined the peak for a frequency of 220 Hz. In this part, you will be determining the peaks for the first 15 harmonics, so 220, 440 and so on. After you have computed the peaks, store this in the array `peaks`. Now, compute the value of each peak **relative** to the fundamental - you can do this by normalizing each peak with respect to the peak of the first harmonic (normalizing just means dividing a bunch of values by one value). For example, ```timbre``` should look something like ```[1, 2.1, 1.8, ... ]```. As a sanity check, make sure your values roughly match the spectral plot.\n",
    "\n",
    "Hint: you will need to use a for loop or a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:02:50.218948Z",
     "start_time": "2021-08-07T06:02:50.177884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign frequencies_15 to an array containing the frequencies corresponding to the first 15 harmonics, so 220, 440...\n",
    "# What numpy tool can you use to do this?\n",
    "frequencies_15 = ...\n",
    "peaks = ...\n",
    "#use as many lines code as you need!\n",
    "for frequency in frequencies_15:\n",
    "    #calculate the peak and store in array peaks\n",
    "    \n",
    "#normalize with respect to the first harmonic\n",
    "timbre = ...\n",
    "print(timbre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d (5 pts )\n",
    "\n",
    "Now, implement ```ttone```, a function that generates a tone of frequency ```freq``` of duration ```samps``` samples with harmonics with relative amplitudes ```timbre```.\n",
    "\n",
    "$$ttone(t) = A_0\\sum_{k=1}^n A_k \\sin (2\\pi k f\\cdot t)$$\n",
    "\n",
    "Notice $kf$ is the frequency of the k-th harmonic and $A_k$ is the k-th element of ``tim``. **Use $A_0$ = 0.08 * maxint**. A smaller normalizing factor is required because the new tone contains many harmonics and will be much louder than the pure tone. \n",
    "\n",
    "**Note: You are creating a function of time. Thus, your function should return as many elements as `t` has. You have computed `t` before using `samps`. You will compute `t` the same way here.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:10:05.328119Z",
     "start_time": "2021-08-07T06:10:05.288488Z"
    }
   },
   "outputs": [],
   "source": [
    "#use as many lines of code as you need!\n",
    "def ttone(freq, samps, tim):\n",
    "    ...\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:10:06.080574Z",
     "start_time": "2021-08-07T06:10:05.923261Z"
    }
   },
   "outputs": [],
   "source": [
    "tim_tone = ttone(220, 2*samplerate, timbre)\n",
    "utils.save(tim_tone)\n",
    "print('Your tone:')\n",
    "ipd.display(ipd.Audio('out/tone.wav', autoplay=True))\n",
    "print('Your tone should sound like: ')\n",
    "ipd.display(ipd.Audio('samples/tim_a.wav', autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Vibrato\n",
    "\n",
    "The synthetic cello is sounding better, but still dull. String players modulate the instrument's pitch by wobbling their finger. This is known as vibrato and causes the pitch of the note to shift slightly. We can simulate vibrato by adding a modulating phase term to each of the harmonics:   \n",
    "\n",
    "$$A_0\\sum_{k=1}^n A_k \\sin \\left[2\\pi k f t + A_v\\sin(2\\pi f_v t)\\right]$$\n",
    "\n",
    "Where $A_v$ corresponds to the amount of Doppler shift and $f_v$ is the frequency of vibrato (corresponding to how fast players move their finger). \n",
    "\n",
    "### 2a (10 pts)\n",
    "\n",
    "Implement the function ``tvtone`` which generates a tone of frequency ```freq``` of duration ```samps``` samples with harmonics with relative amplitudes ```tim```, and vibrato of frequency ``vib_freq`` and amplitude ``vib_amp``.\n",
    "\n",
    "Hint: remember that numpy operations are element-wise\n",
    "```python\n",
    "# element-wise \n",
    ">>> a = np.array([2,3,4])\n",
    ">>> b = np.array([5,6,7])\n",
    ">>> a+b\n",
    "[7, 9, 11]\n",
    "\n",
    "# broadcasted element-wise (see lecture notes 5 appendix A)\n",
    ">>> 2+a\n",
    "[4, 5, 6]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:10:24.242074Z",
     "start_time": "2021-08-07T06:10:24.200992Z"
    }
   },
   "outputs": [],
   "source": [
    "def tvtone(samps, freq, tim, vib_freq, vib_amp):\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:10:25.628510Z",
     "start_time": "2021-08-07T06:10:25.535704Z"
    }
   },
   "outputs": [],
   "source": [
    "vib_tone = tvtone(2*samplerate, 220, timbre, 6, 2)\n",
    "utils.save(vib_tone)\n",
    "print('Your tone:')\n",
    "ipd.display(ipd.Audio('out/tone.wav', autoplay=True))\n",
    "print('Your tone should sound like: ')\n",
    "ipd.display(ipd.Audio('samples/vib_a.wav', autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b (5 pts)\n",
    "\n",
    "Play around with the values of `vib_freq` and `vib_amp` until it sounds natural. You can generate some really wobbly sounds, but we found `vib_freq=4` and `vib_amp=1.5` to be good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:11:10.879132Z",
     "start_time": "2021-08-07T06:11:10.797155Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vib_tone = ...\n",
    "utils.save(vib_tone)\n",
    "ipd.Audio('out/tone.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c (5 pts)\n",
    "\n",
    "Plot the Fourier transform of `vib_tone` and describe how to compares to the spectrum of the real cello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:11:17.102483Z",
     "start_time": "2021-08-07T06:11:16.415497Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot here. Check how Fourier transforms were previously plotted. Use help if you need to. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: ADSR\n",
    "\n",
    "Even with vibrato, the synthetic cello tone sounds dull. One reason is because a real instrument does not have constant volume. We can model the the \"micro-dynamics\" of a note with the ADSR envelope.\n",
    "\n",
    "1. **Attack:**  the time it takes arrive at maximum volume at the start of the note.\n",
    "\n",
    "2. **Decay:**   there is generally some decay in volume after the attack\n",
    "\n",
    "3. **Sustain:** after the decay, the volume is sustained for the majority of the note  \n",
    "\n",
    "4. **Release:** the time it takes for the note to transition from the sustain volume to silence at the end of the note   \n",
    "\n",
    "<img src=\"fig/adsr.png\"  style=\"width: 450px;\"/>\n",
    "\n",
    "The attack, delay, and release parts of ADSR do not have to be linear (as in the figure above), but for the sake of simplicity, let's assume that they are. Furthermore, let's assume there is no delay. Instead, our ADSR envelope is fully specified by the attack time $t_a$ from zero to full volume and the release time $t_r$ from full volume back to zero.\n",
    "\n",
    "<img src=\"fig/env.png\"  style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a (10 pts)\n",
    "\n",
    "Implement the function ``tvetone`` which generates a tone of frequency ```freq``` of duration ```samps``` with harmonics of relative amplitudes ```tim```, vibrato of ``vib_freq``, ``vib_amp``; and attack time `ta`and release time `tr`.\n",
    "\n",
    "In other words, you will need to multiply the `tvtone` by an ADSR envelope. The envelope should have value 1 during the sustain portion and rise/fall linearly in the attack/release sections. So what is really happening here? You are simply scaling your data.\n",
    "\n",
    "Note: There should NOT be any for loops in your function.\n",
    "\n",
    "`ta` = attack time. Until the attack time, there should be a linear increase. Thus your data should be scaled from 0 to 1 uptil this point.\n",
    "\n",
    "Between `ta` and `tr`, your data is the same. \n",
    "\n",
    "`tr` = release time. From this point on, your data should scale linearly from 1 to 0. \n",
    "\n",
    "\n",
    "How can we linearly scale data? To do this, we create an `envelope` array that we will simply multiply with the data (remember that numpy does element-wise operation!\n",
    "\n",
    "\n",
    "```python\n",
    "# element-wise \n",
    ">>> a = np.array([2,3,4])\n",
    ">>> b = np.array([5,6,7])\n",
    ">>> a*b\n",
    "[10, 18, 28]\n",
    "\n",
    "```\n",
    "To create linear scalings, try to think about how you can use `np.linspace`. You have already used this before - if you want to create an array of `x` values equally spaced between `a` and `b`, you call `np.linspace(a, b, x)`.\n",
    "\n",
    "Hint: recall the number of samples for some time $t$ is $t\\cdot$ samplerate\n",
    "Hint: `np.ones` might be useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:13:44.010625Z",
     "start_time": "2021-08-07T06:13:43.982028Z"
    }
   },
   "outputs": [],
   "source": [
    "# use the function tvtone that you have already define to compute the tvtone!\n",
    "def tvetone(samps, freq, tim, vib_freq, vib_amp, ta, tr):\n",
    "    # use as many lines of code as you need\n",
    "    \n",
    "    data = ...\n",
    "    \n",
    "    # number of samples for attack and release time\n",
    "    sa = int(...)\n",
    "    sr = int(...)\n",
    "    \n",
    "    envelope = ...\n",
    "    ...\n",
    "    return envelope*data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:13:45.264271Z",
     "start_time": "2021-08-07T06:13:45.154933Z"
    }
   },
   "outputs": [],
   "source": [
    "adsr_tone = tvetone(2*samplerate, 220, timbre, 4, 1.5, 0.5, 0.5)\n",
    "utils.save(adsr_tone)\n",
    "print('Your tone:')\n",
    "ipd.display(ipd.Audio('out/tone.wav', autoplay=True))\n",
    "print('Your tone should sound like: ')\n",
    "ipd.display(ipd.Audio('samples/adsr_a.wav', autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b (5 pts)\n",
    "\n",
    "Play around with the values of `vib_freq`, `vib_amp`, `ta`, and `tr` until it sounds natural. We found `vib_freq=4`, `vib_amp=1.5`, `ta=0.05`, and `tr=0.15` to be good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:13:56.947386Z",
     "start_time": "2021-08-07T06:13:56.862340Z"
    }
   },
   "outputs": [],
   "source": [
    "adsr_tone = ...\n",
    "utils.save(adsr_tone)\n",
    "ipd.display(ipd.Audio('out/tone.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Pachelbel Canon in D for 4 Cellos (0 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make further improvements to our cello synthesizer. For example, we can add a bit of reverberation, make the vibrato more dynamic, etc. \n",
    "\n",
    "To finish off this module, synthesize [Pachelbel's Canon in D for 4 cellos](fig/canon_D_cellos.pdf). In the `utils` module, we have provided a function `pachelbel_canon_D`. Read the docstring and run the cell below. This function simply calls the tone-generating function we created in the previous exercises to generate the first 15-bars of the Canon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:27:57.406547Z",
     "start_time": "2021-08-07T06:27:54.765068Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.pachelbel_canon_D(tvetone, timbre, mono=True) \n",
    "ipd.Audio('out/Pachelbel_Canon_D.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:25:50.369065Z",
     "start_time": "2021-08-04T08:25:50.300993Z"
    }
   },
   "source": [
    "This is what our files sound like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T06:28:41.577043Z",
     "start_time": "2021-08-07T06:28:41.290616Z"
    }
   },
   "outputs": [],
   "source": [
    "ipd.display(ipd.Audio('samples/stereo.wav', autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Check to make sure that you have answered all questions. Run all the cells so that all output is visible. Finally, export this notebook as a PDF (File/Download As/PDF via LaTeX (.pdf)) and submit to bCourses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>References:</b> Edited and complied by the ULAB staff. \n",
    "1. https://www.kdnuggets.com/2020/02/audio-data-analysis-deep-learning-python-part-1.html\n",
    "2. https://commons.wikimedia.org/wiki/File:Anatomy_of_Human_Ear_with_Cochlear_Frequency_Mapping.svg\n",
    "\n",
    "Last Updated: August 2021"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
